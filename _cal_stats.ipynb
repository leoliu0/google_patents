{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: google patents tables\n",
    "# output: pat_metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/24 17:29:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = spark_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.set_option(\"compute.default_index_type\", \"distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/nas/google_patent/google_patent/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read IPC table and take the first 4 digits as ipc4 classification\n",
    "ipc = spark_pq(path + \"ipc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc = ipc.withColumn(\"ipc4\", F.substring(\"ipc\", 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_scope = ipc.select(\"patnum\", \"ipc4\").drop_duplicates()\n",
    "patent_scope = (\n",
    "    patent_scope.groupby([\"patnum\"])\n",
    "    .agg(F.countDistinct(\"ipc4\").alias(\"scope\"))\n",
    "    .to_pandas_on_spark()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in patent information\n",
    "pat = spark_pq(path + \"patent\").select(\"patnum\", \"grant_date\").filter(\"grant_date>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pat.withColumn(\n",
    "    \"grant_date\",\n",
    "    F.to_timestamp(F.col(\"grant_date\").cast(StringType()), \"yyyyMMdd\").cast(DateType()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read citation table, keep US patents and only utility patents\n",
    "cite = spark.sql(\n",
    "    f\"\"\"select patnum,cast(pub_number as integer) as citation \n",
    "        from parquet.`{path+'citation'}` where country='US' order by patnum\"\"\"\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find grant date for citing patents\n",
    "cite = cite.join(pat, \"patnum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pat.withColumnRenamed(\"patnum\", \"citation\").withColumnRenamed(\n",
    "    \"grant_date\", \"grant_date_cite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find grant date for cited patents\n",
    "cite = cite.join(pat, \"citation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = cite.withColumn(\n",
    "    \"days\", F.datediff(F.col(\"grant_date\"), F.col(\"grant_date_cite\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite = cite.to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcite = cite.groupby(\"patnum\").citation.nunique().rename(\"bcite\").reset_index()\n",
    "fcite = cite.groupby(\"citation\").patnum.nunique().rename(\"fcite\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcite.columns = [\"patnum\", \"fcite\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[citation: int, grant_date_cite: date]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ipc.select(\"patnum\", F.substring(\"ipc\", 1, 4).alias(\"tech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakthru = (\n",
    "    fcite.to_spark()\n",
    "    .join(x, on=[\"patnum\"])\n",
    "    .join(pat.withColumnRenamed(\"citation\", \"patnum\"), on=[\"patnum\"])\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakthru = breakthru.withColumn(\"year\", F.year(\"grant_date_cite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakthru = breakthru.select(\n",
    "    \"patnum\",'fcite',\n",
    "    F.percent_rank()\n",
    "    .over(Window.partitionBy([\"tech\", \"year\"]).orderBy(F.col('fcite').desc()))\n",
    "    .alias(\"perc\"),\n",
    ").filter(\"perc<0.01\").select('patnum').drop_duplicates().withColumn('breakthru',F.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc = ipc.select(\"patnum\", \"ipc\", \"ipc4\").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gener = cite[cite.days < 3650]  # for generality, use recent 10 years of forw. citations\n",
    "gener = gener[[\"patnum\", \"citation\"]].merge(ipc)\n",
    "gener.columns = [\"citation\", \"patnum\", \"ipc\", \"ipc4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = gener.merge(gener.groupby([\"patnum\"]).ipc.nunique().rename(\"Tin\").reset_index())\n",
    "beta = beta.merge(\n",
    "    gener.groupby([\"patnum\", \"ipc4\"]).ipc.nunique().rename(\"Tjin\").reset_index()\n",
    ")\n",
    "beta[\"beta\"] = beta.Tjin / beta.Tin\n",
    "\n",
    "beta = beta[[\"patnum\", \"ipc4\", \"beta\"]].drop_duplicates()\n",
    "\n",
    "gener = gener[[\"patnum\", \"citation\", \"ipc4\"]].drop_duplicates()\n",
    "gener = gener.merge(beta).groupby([\"patnum\", \"ipc4\"]).beta.mean().reset_index()\n",
    "gener.beta = gener.beta ** 2\n",
    "gener = (1 - gener.groupby(\"patnum\").beta.sum().rename(\"generality\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgin = cite[[\"patnum\", \"citation\"]].merge(ipc.rename({\"patnum\": \"citation\"}, axis=1))\n",
    "orgin = orgin[[\"patnum\", \"citation\", \"ipc\"]].drop_duplicates()\n",
    "orgin = (\n",
    "    orgin[[\"patnum\", \"ipc\"]]\n",
    "    .drop_duplicates()\n",
    "    .merge(orgin.groupby([\"patnum\", \"ipc\"]).ipc.size().rename(\"spj\").reset_index())\n",
    ")\n",
    "orgin = orgin[[\"patnum\", \"spj\"]].merge(\n",
    "    orgin.groupby([\"patnum\"]).spj.sum().rename(\"sum_spj\").reset_index()\n",
    ")\n",
    "orgin[\"sum_spj\"] = (orgin.spj / orgin.sum_spj) ** 2\n",
    "\n",
    "orgin = (1 - orgin.groupby(\"patnum\").sum_spj.sum().rename(\"orginality\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = spark.sql(\n",
    "    f\"\"\"select patnum,count(claims) as num_claims \n",
    "                    from parquet.`{path+'claims'}` group by patnum\"\"\"\n",
    ").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "patstat = (\n",
    "    patent_scope.merge(fcite, how=\"left\")\n",
    "    .merge(bcite, how=\"left\")\n",
    "    .fillna(0)\n",
    "    .merge(gener, how=\"left\")\n",
    "    .merge(orgin, how=\"left\")\n",
    "    .merge(claims, how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc = spark.sql(\n",
    "    f\"\"\"select patnum,substr(ipc,1,4)as ipc4,count(substr(ipc,1,4)) as n from parquet.`{path+'ipc'}`\n",
    "                    group by patnum,ipc4 order by patnum,n desc\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc = ipc.drop_duplicates([\"patnum\"]).select(\"patnum\", \"ipc4\").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant = sp.read_parquet(path + \"patent\", columns=[\"patnum\", \"grant_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grant.merge(patstat, how=\"left\").merge(ipc, how=\"left\").merge(breakthru.to_pandas_on_spark(),how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.breakthru.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:(119 + 81) / 200][Stage 84:>(0 + 47) / 200][Stage 86:> (0 + 0) / 200]]\r"
     ]
    }
   ],
   "source": [
    "df.to_parquet(\"pat_metrics.pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rpq(\"pat_metrics.pa/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
